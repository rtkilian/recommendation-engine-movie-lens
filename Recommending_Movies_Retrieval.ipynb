{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommending Movies - Retrieval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbHBt8Og5J4nucFALotiZx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtkilian/recommendation-engine-movie-lens/blob/main/Recommending_Movies_Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r2ELNpxja1v"
      },
      "source": [
        "# Recommending movies: retrieval\r\n",
        "Real-world recommender systems are often made up of two tasks:\r\n",
        "1. Retrieval: select an initial set of hundreds of candidates from all possible candidates. This needs to be computationally efficient.\r\n",
        "2. Ranking: takes the output of the retrieval model and fine-tunes them to select only the best. \r\n",
        "\r\n",
        "Retrieval models are often composed of two sub-models:\r\n",
        "1. Query model: computes the query representation (normally a fixed-dimensionality embedding vector) using query features.\r\n",
        "2. Candidate model: computes the candidate representation (an equally-sized vector) using the candidate features\r\n",
        "\r\n",
        "The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query.\r\n",
        "\r\n",
        "In this notebook, I am going to build a two-tower model using the Movielens dataset. I will:\r\n",
        "1. Get the data and split into a training and test set.\r\n",
        "2. Implement a retrieval model.\r\n",
        "3. Fit and evaluate the model.\r\n",
        "4. Export the model for efficient serving by building an approximate nearest neighbours (ANN) index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oH9KhX-lJ26"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8RYtmlTlM5Q"
      },
      "source": [
        "!pip install -q numpy==1.18.5 # we have to downgrade otherwise we get an error\r\n",
        "\r\n",
        "!pip install -q tensorflow-recommenders\r\n",
        "!pip install -q --upgrade tensorflow-datasets\r\n",
        "!pip install -q scann"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgY9V7-hlXJh",
        "outputId": "8ca1405a-9e7c-4885-f6d5-57e31810f79f"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "print(np.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.18.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvr-xBZxnf_N"
      },
      "source": [
        "import os\r\n",
        "import pprint\r\n",
        "import tempfile\r\n",
        "\r\n",
        "from typing import Dict, Text\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DEUaQu-ntdX"
      },
      "source": [
        "import tensorflow_recommenders as tfrs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlVdj7TLkuQz"
      },
      "source": [
        "## Data\r\n",
        "We can use the Movielens data in two ways:\r\n",
        "1. Explicitly: use the ratings from 1-5\r\n",
        "2. Implicitly: binary of 0 or 1, where 1=the user has watched the movie\r\n",
        "\r\n",
        "We are going to use the latter.\r\n",
        "\r\n",
        "We are going to use the data with 100k ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--_vp_zDktIZ"
      },
      "source": [
        "# Ratings data\r\n",
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\") # this data does not have any predefined splits\r\n",
        "\r\n",
        "# Features of all the available movies\r\n",
        "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}